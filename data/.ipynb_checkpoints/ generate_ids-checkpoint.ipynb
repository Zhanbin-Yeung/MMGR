{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad22c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('annotations/coco_train.json', 'r') as coco_train_json:\n",
    "    coco_train = json.load(coco_train_json)\n",
    "with open('annotations/coco_val.json', 'r') as coco_val_json:\n",
    "    coco_val = json.load(coco_val_json)\n",
    "with open('annotations/coco_test.json', 'r') as coco_test_json:\n",
    "    coco_test = json.load(coco_test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ebe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b66fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_caption = dict()\n",
    "row = 0\n",
    "image_list = list()\n",
    "caption_list = list()\n",
    "for temp in coco_train:\n",
    "    image = temp['image']\n",
    "    caption = temp['caption']\n",
    "    caption_list.append(caption)\n",
    "    if image not in image_caption.keys():\n",
    "        image_caption[image] = [row]\n",
    "        image_list.append(image)\n",
    "    else:\n",
    "        image_caption[image].append(row)\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different from training dataset, in the validation and testing sets, each item consists of the file_name of images and their caption list.\n",
    "for temp in coco_val:\n",
    "    image = temp['image']\n",
    "    temp_caption_list = temp['caption']\n",
    "    image_list.append(image)\n",
    "    caption_list.extend(temp_caption_list)\n",
    "    if image not in image_caption.keys():\n",
    "        image_caption[image] = list(range(row, row+len(temp_caption_list)))\n",
    "    row += len(temp_caption_list)\n",
    "\n",
    "for temp in coco_test:\n",
    "    image = temp['image']\n",
    "    temp_caption_list = temp['caption']\n",
    "    image_list.append(image)\n",
    "    caption_list.extend(temp_caption_list)\n",
    "    if image not in image_caption.keys():\n",
    "        image_caption[image] = list(range(row, row+len(temp_caption_list)))\n",
    "    row += len(temp_caption_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbd0c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_embed = np.load('caption_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part aims to implement the image embedding calculation by aggregating the embeddings of its captions. The code is adopted on the training set. \n",
    "# Here, we list all the images in training set. For each image, its row (i.e., index) in the image_list corresponds to the row of its caption in caption_list. \n",
    "# Therefore, we can use the index to extract the embedding vector from caption_embed. \n",
    "image_id_list = list()\n",
    "for temp in coco_train:\n",
    "    image_id_list.append(temp['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f9f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_caption_dict is build to store the image_name and the sum of its captions' embeddings.\n",
    "# id_num_dict is to store the image_name the numbers of its captions.\n",
    "id_caption_dict = dict()\n",
    "id_num_dict = dict()\n",
    "for index in range(len(image_id_list)):\n",
    "    image_id = image_id_list[index]\n",
    "    if image_id not in id_caption_dict.keys():\n",
    "        id_caption_dict[image_id] = caption_embed[index]\n",
    "        id_num_dict[image_id] = 1\n",
    "    else:\n",
    "        id_caption_dict[image_id] += caption_embed[index]\n",
    "        id_num_dict[image_id] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed9e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('id_caption_dict.npy', np.array(id_caption_dict))\n",
    "np.save('id_num_dict.npy', np.array(id_num_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we can compute the representation vectors of images.\n",
    "train_image_embed = list()\n",
    "for key in id_caption_dict.keys():\n",
    "    train_image_embed.append(id_caption_dict[key]/id_num_dict[key])\n",
    "\n",
    "train_image_embed = np.array(train_image_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299bd6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As for validation and testing sets, we can easily compute the images' vectors with the embedding matrix of captions. Because each image has five captions. \n",
    "val_caption_embed = caption_embed[-10000: -5000]\n",
    "test_caption_embed = caption_embed[-5000:]\n",
    "\n",
    "new_val_caption_embed = val_caption_embed.reshape([-1, 5, 1536])\n",
    "new_test_caption_embed = test_caption_embed.reshape([-1, 5, 1536])\n",
    "\n",
    "val_image_embed = new_val_caption_embed.mean(1)\n",
    "test_image_embed = new_test_caption_embed.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705912f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123287, 1536)\n"
     ]
    }
   ],
   "source": [
    "# generating the image embedding matrix by concatenating the embeddings in training, validation, testing sets. \n",
    "image_embed = np.concatenate([train_image_embed, val_caption_embed, test_caption_embed], axis=0)\n",
    "print(np.shape(image_embed))\n",
    "np.save('image_embed.npy', image_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613f810-ec8b-4ff1-ab6f-d0c509d06e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123287, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embed = torch.load('bert_img_embeds.pt')\n",
    "image_embed = image_embed.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a396a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 伪代码中的生成语义ID函数\n",
    "def generate_semantic_ids(X, k, c, cnt=0, J_x=None, absolute_indices=None):\n",
    "    cnt += 1\n",
    "    if absolute_indices is None:\n",
    "        absolute_indices = np.arange(len(X))\n",
    "\n",
    "    if J_x is None:\n",
    "        J_x = []\n",
    "    # 步骤C1：使用K均值聚类算法将文档嵌入向量X聚类成k个簇\n",
    "    kmeans = KMeans(n_clusters=k, n_jobs=-1)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    # print(labels)\n",
    "    J = []\n",
    "\n",
    "    # 步骤C2：循环遍历每个簇\n",
    "    for i in range(k):\n",
    "        current_cluster_indices = np.where(labels == i)[0]\n",
    "        current_cluster_size = len(current_cluster_indices)\n",
    "        idx = ' ' + str(i)\n",
    "        J_current = [idx] * current_cluster_size\n",
    "        \n",
    "        if current_cluster_size > c:\n",
    "            # 步骤C3：递归生成子簇的语义ID\n",
    "            J_rest, J_x = generate_semantic_ids(X[current_cluster_indices], 10, 10, cnt, J_x, absolute_indices[current_cluster_indices])\n",
    "        else:\n",
    "            # 步骤C4：生成当前簇的语义ID\n",
    "            J_rest = [str(j) for j in range(current_cluster_size)]\n",
    "            J_x.extend(absolute_indices[current_cluster_indices])\n",
    "        \n",
    "        # print(J_rest)\n",
    "        \n",
    "        # 步骤C5：将J_current和J_rest逐元素拼接成J_cluster\n",
    "        J_cluster = [a + b for a, b in zip(J_rest, J_current)]\n",
    "        \n",
    "        # 将J_cluster中的语义ID添加到J列表中\n",
    "        J.extend(J_cluster)\n",
    "\n",
    "    return J, J_x\n",
    "\n",
    "# 设定聚类簇数k和阈值c\n",
    "k = 100\n",
    "c = 100\n",
    "\n",
    "# 调用生成语义ID函数\n",
    "image_ids, image_idx = generate_semantic_ids(image_embed, k, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e044b-d7f7-42a4-a7a1-62f835f4890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = [' '.join(image_id.split()[::-1]) for image_id in image_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d34843a-940b-413d-b456-3e1d457c467e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 1 0 5 0'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ids[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb4558-3faf-4b9e-a5eb-468cf7b6ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list_of_strings = []\n",
    "for image_id in image_ids:\n",
    "    numbers = image_id.split(\" \")\n",
    "    new_numbers = [str(int(n) + (1 if i > 0 else 0) * (100 + (i - 1) * 10)) for i, n in enumerate(numbers)]\n",
    "    new_string = \" \".join(map(str, new_numbers)) \n",
    "    new_list_of_strings.append(new_string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82defe04-200f-4098-8f75-8373bb32bd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2385\n"
     ]
    }
   ],
   "source": [
    "def count_duplicate_elements(input_list):\n",
    "    element_count = {}\n",
    "    duplicate_count = 0\n",
    "\n",
    "    for sublist in input_list:\n",
    "        sublist_tuple = tuple(sublist)\n",
    "        if sublist_tuple in element_count:\n",
    "            element_count[sublist_tuple] += 1\n",
    "            if element_count[sublist_tuple] == 2:\n",
    "                duplicate_count += 1\n",
    "        else:\n",
    "            element_count[sublist_tuple] = 1\n",
    "\n",
    "    return element_count, duplicate_count\n",
    "\n",
    "new_id = np.load('new_id.npy')\n",
    "\n",
    "# input_list = [[1,2,3],[2,3,4],[1,2,3],[2,3,5]]\n",
    "element_count, duplicate_count = count_duplicate_elements(list(new_id))\n",
    "print(duplicate_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5a91b-0c6f-431a-b7aa-b7fe2993bab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120751\n"
     ]
    }
   ],
   "source": [
    "print(len(element_count.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292116f-cfb3-4460-bfce-c61d54461fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 101 110 125 130'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list_of_strings[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc787db-8d3b-452d-82a2-ce46f39a2a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = new_list_of_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84898b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 伪代码中的生成语义ID函数\n",
    "def generate_semantic_ids(X, k):\n",
    "    kmeans = KMeans(n_clusters=k, n_jobs=-1)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    return labels\n",
    "\n",
    "# 设定聚类簇数k\n",
    "k = 100\n",
    "\n",
    "feat_dim = image_embed.shape[1]\n",
    "head = 4\n",
    "head_dim = feat_dim // head\n",
    "label_list = []\n",
    "for i in range(head):\n",
    "    start = i * head_dim\n",
    "    end = start + head_dim\n",
    "    X = image_embed[:,start:end]\n",
    "    labels = generate_semantic_ids(X, k)\n",
    "    labels = [str(label+(i*k)) for label in labels]\n",
    "    label_list.append(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f06763",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [''] * image_embed.shape[0]\n",
    "for i, labels in enumerate(label_list):\n",
    "    for j, label in enumerate(labels):\n",
    "        if i == 0:\n",
    "            ids[j] += label\n",
    "        else:\n",
    "            ids[j] += (' '+label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec4d5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 4849\n"
     ]
    }
   ],
   "source": [
    "def find_duplicates(lst):\n",
    "    seen = set()\n",
    "    duplicates = set()\n",
    "    for item in lst:\n",
    "        if item in seen:\n",
    "            duplicates.add(item)\n",
    "        else:\n",
    "            seen.add(item)\n",
    "    return duplicates\n",
    "\n",
    "\n",
    "duplicates = find_duplicates(ids)\n",
    "\n",
    "print(\"Duplicates:\", len(duplicates))  # 输出将包括所有重复的元素\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af7416",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"image_ids.json\", 'r') as f:\n",
    "    image_ids = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = np.load(\"image_idx.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc47f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = sorted(zip(image_ids, image_idx), key=lambda x: x[1])\n",
    "\n",
    "sorted_image_ids, sorted_image_idx = zip(*combined)\n",
    "sorted_image_ids = list(sorted_image_ids)\n",
    " \n",
    "img_caption_ids = [None] * len(caption_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec60d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_caption_ids = []\n",
    "test_img_caption_ids = []\n",
    "\n",
    "for i, (img_id, img_idx) in enumerate(zip(sorted_image_ids, sorted_image_idx)):\n",
    "    img_name = image_list[img_idx]\n",
    "    caption_indices = image_caption[img_name]\n",
    "    sorted_image_ids[i] += ' 0'\n",
    "    \n",
    "    caption_ids = []\n",
    "    for j, caption_idx in enumerate(caption_indices, start=1):\n",
    "        caption_id = img_id + ' ' + str(j)\n",
    "        caption_ids.append(caption_id)\n",
    "        img_caption_ids[caption_idx] = (sorted_image_ids[i], caption_id)\n",
    "        \n",
    "    if len(sorted_image_ids) - 10000 <= i < len(sorted_image_ids) - 5000:\n",
    "        val_img_caption_ids.append((sorted_image_ids[i], caption_ids))\n",
    "    if i >= len(sorted_image_ids) - 5000:\n",
    "        test_img_caption_ids.append((sorted_image_ids[i], caption_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad267f9-5ef9-4002-a480-636d42dc9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('img_caption_ids.json', 'w') as f:\n",
    "    json.dump(img_caption_ids, f)\n",
    "\n",
    "with open('val_img_caption_ids.json', 'w') as f:\n",
    "    json.dump(val_img_caption_ids, f)\n",
    "    \n",
    "with open('test_img_caption_ids.json', 'w') as f:\n",
    "    json.dump(test_img_caption_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe775f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['42 106 114 128 130 1',\n",
       " '42 106 114 128 130 2',\n",
       " '42 106 114 128 130 3',\n",
       " '42 106 114 128 130 4',\n",
       " '42 106 114 128 130 5']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_img_caption_ids[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d9ac0-29f0-49e4-bfea-07a022e746e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
